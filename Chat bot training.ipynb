{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import SGD\n",
    "import random\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =[]\n",
    "classes =[]\n",
    "document = []\n",
    "ignore_words = ['?' , '!']\n",
    "data_file = open('Dummy.json').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        #print(pattern)\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        document.append((w , intent['tag']))\n",
    "        \n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "classes = sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words , open('words.pkl' , 'wb'))\n",
    "pickle.dump(classes , open('classes.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output_empty = [0]*len(classes)\n",
    "for doc in document:\n",
    "    bag =[]\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    \n",
    "    for w in words :\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    \n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    \n",
    "    training.append([bag , output_row])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "669/669 [==============================] - 1s 1ms/step - loss: 3.6796 - accuracy: 0.0538\n",
      "Epoch 2/100\n",
      "669/669 [==============================] - 0s 686us/step - loss: 3.4792 - accuracy: 0.0897\n",
      "Epoch 3/100\n",
      "669/669 [==============================] - 1s 801us/step - loss: 3.1358 - accuracy: 0.1644\n",
      "Epoch 4/100\n",
      "669/669 [==============================] - 0s 742us/step - loss: 2.6898 - accuracy: 0.2930\n",
      "Epoch 5/100\n",
      "669/669 [==============================] - 0s 702us/step - loss: 2.3715 - accuracy: 0.3468\n",
      "Epoch 6/100\n",
      "669/669 [==============================] - 0s 716us/step - loss: 2.0533 - accuracy: 0.4111\n",
      "Epoch 7/100\n",
      "669/669 [==============================] - 0s 694us/step - loss: 1.8394 - accuracy: 0.4813\n",
      "Epoch 8/100\n",
      "669/669 [==============================] - 1s 763us/step - loss: 1.6148 - accuracy: 0.5396\n",
      "Epoch 9/100\n",
      "669/669 [==============================] - 0s 742us/step - loss: 1.4520 - accuracy: 0.5770\n",
      "Epoch 10/100\n",
      "669/669 [==============================] - 0s 718us/step - loss: 1.4176 - accuracy: 0.5815\n",
      "Epoch 11/100\n",
      "669/669 [==============================] - 1s 779us/step - loss: 1.1544 - accuracy: 0.6741\n",
      "Epoch 12/100\n",
      "669/669 [==============================] - 0s 737us/step - loss: 1.0965 - accuracy: 0.6741\n",
      "Epoch 13/100\n",
      "669/669 [==============================] - 0s 692us/step - loss: 1.0881 - accuracy: 0.6756\n",
      "Epoch 14/100\n",
      "669/669 [==============================] - 1s 795us/step - loss: 0.9952 - accuracy: 0.6921\n",
      "Epoch 15/100\n",
      "669/669 [==============================] - 0s 695us/step - loss: 0.9471 - accuracy: 0.7010\n",
      "Epoch 16/100\n",
      "669/669 [==============================] - 0s 724us/step - loss: 0.8973 - accuracy: 0.7280\n",
      "Epoch 17/100\n",
      "669/669 [==============================] - 1s 826us/step - loss: 0.8447 - accuracy: 0.7578\n",
      "Epoch 18/100\n",
      "669/669 [==============================] - 0s 717us/step - loss: 0.7884 - accuracy: 0.7713\n",
      "Epoch 19/100\n",
      "669/669 [==============================] - 0s 680us/step - loss: 0.8305 - accuracy: 0.7504\n",
      "Epoch 20/100\n",
      "669/669 [==============================] - 0s 678us/step - loss: 0.7346 - accuracy: 0.7668\n",
      "Epoch 21/100\n",
      "669/669 [==============================] - 0s 715us/step - loss: 0.7003 - accuracy: 0.7892\n",
      "Epoch 22/100\n",
      "669/669 [==============================] - 0s 696us/step - loss: 0.7494 - accuracy: 0.7758\n",
      "Epoch 23/100\n",
      "669/669 [==============================] - 1s 787us/step - loss: 0.6424 - accuracy: 0.8042\n",
      "Epoch 24/100\n",
      "669/669 [==============================] - 0s 718us/step - loss: 0.6569 - accuracy: 0.7848\n",
      "Epoch 25/100\n",
      "669/669 [==============================] - 0s 702us/step - loss: 0.6549 - accuracy: 0.7997\n",
      "Epoch 26/100\n",
      "669/669 [==============================] - 0s 731us/step - loss: 0.5514 - accuracy: 0.8281\n",
      "Epoch 27/100\n",
      "669/669 [==============================] - 0s 735us/step - loss: 0.5307 - accuracy: 0.8386\n",
      "Epoch 28/100\n",
      "669/669 [==============================] - 1s 777us/step - loss: 0.5084 - accuracy: 0.8401\n",
      "Epoch 29/100\n",
      "669/669 [==============================] - 0s 712us/step - loss: 0.4488 - accuracy: 0.8744\n",
      "Epoch 30/100\n",
      "669/669 [==============================] - 1s 748us/step - loss: 0.4564 - accuracy: 0.8505\n",
      "Epoch 31/100\n",
      "669/669 [==============================] - 0s 699us/step - loss: 0.4646 - accuracy: 0.8700\n",
      "Epoch 32/100\n",
      "669/669 [==============================] - 0s 700us/step - loss: 0.4588 - accuracy: 0.8714\n",
      "Epoch 33/100\n",
      "669/669 [==============================] - 1s 784us/step - loss: 0.5339 - accuracy: 0.8416\n",
      "Epoch 34/100\n",
      "669/669 [==============================] - 0s 673us/step - loss: 0.4088 - accuracy: 0.8909\n",
      "Epoch 35/100\n",
      "669/669 [==============================] - 0s 679us/step - loss: 0.4769 - accuracy: 0.8625\n",
      "Epoch 36/100\n",
      "669/669 [==============================] - 0s 737us/step - loss: 0.4800 - accuracy: 0.8535\n",
      "Epoch 37/100\n",
      "669/669 [==============================] - 0s 700us/step - loss: 0.4603 - accuracy: 0.8655\n",
      "Epoch 38/100\n",
      "669/669 [==============================] - 0s 676us/step - loss: 0.4314 - accuracy: 0.8700\n",
      "Epoch 39/100\n",
      "669/669 [==============================] - 1s 782us/step - loss: 0.3039 - accuracy: 0.9013\n",
      "Epoch 40/100\n",
      "669/669 [==============================] - 0s 705us/step - loss: 0.4548 - accuracy: 0.8550\n",
      "Epoch 41/100\n",
      "669/669 [==============================] - 0s 671us/step - loss: 0.4324 - accuracy: 0.8714\n",
      "Epoch 42/100\n",
      "669/669 [==============================] - 0s 720us/step - loss: 0.4020 - accuracy: 0.8774\n",
      "Epoch 43/100\n",
      "669/669 [==============================] - 1s 768us/step - loss: 0.4471 - accuracy: 0.8685\n",
      "Epoch 44/100\n",
      "669/669 [==============================] - 1s 805us/step - loss: 0.3705 - accuracy: 0.8744\n",
      "Epoch 45/100\n",
      "669/669 [==============================] - 1s 798us/step - loss: 0.3417 - accuracy: 0.8999\n",
      "Epoch 46/100\n",
      "669/669 [==============================] - 1s 781us/step - loss: 0.3299 - accuracy: 0.8984\n",
      "Epoch 47/100\n",
      "669/669 [==============================] - 0s 653us/step - loss: 0.4111 - accuracy: 0.8714\n",
      "Epoch 48/100\n",
      "669/669 [==============================] - 0s 731us/step - loss: 0.3159 - accuracy: 0.8999\n",
      "Epoch 49/100\n",
      "669/669 [==============================] - 1s 804us/step - loss: 0.3488 - accuracy: 0.8849\n",
      "Epoch 50/100\n",
      "669/669 [==============================] - 1s 809us/step - loss: 0.3830 - accuracy: 0.8924\n",
      "Epoch 51/100\n",
      "669/669 [==============================] - 1s 842us/step - loss: 0.4001 - accuracy: 0.8969\n",
      "Epoch 52/100\n",
      "669/669 [==============================] - 0s 745us/step - loss: 0.3551 - accuracy: 0.8939\n",
      "Epoch 53/100\n",
      "669/669 [==============================] - 0s 677us/step - loss: 0.3972 - accuracy: 0.8774\n",
      "Epoch 54/100\n",
      "669/669 [==============================] - 0s 694us/step - loss: 0.3311 - accuracy: 0.8984\n",
      "Epoch 55/100\n",
      "669/669 [==============================] - 1s 783us/step - loss: 0.3005 - accuracy: 0.8954\n",
      "Epoch 56/100\n",
      "669/669 [==============================] - 1s 842us/step - loss: 0.3511 - accuracy: 0.8969\n",
      "Epoch 57/100\n",
      "669/669 [==============================] - 1s 798us/step - loss: 0.3828 - accuracy: 0.8894\n",
      "Epoch 58/100\n",
      "669/669 [==============================] - 0s 724us/step - loss: 0.3440 - accuracy: 0.8864\n",
      "Epoch 59/100\n",
      "669/669 [==============================] - 1s 828us/step - loss: 0.3013 - accuracy: 0.8939\n",
      "Epoch 60/100\n",
      "669/669 [==============================] - 1s 813us/step - loss: 0.2887 - accuracy: 0.9178\n",
      "Epoch 61/100\n",
      "669/669 [==============================] - 1s 754us/step - loss: 0.3239 - accuracy: 0.9088\n",
      "Epoch 62/100\n",
      "669/669 [==============================] - 0s 739us/step - loss: 0.3851 - accuracy: 0.8909\n",
      "Epoch 63/100\n",
      "669/669 [==============================] - 1s 766us/step - loss: 0.3023 - accuracy: 0.8954\n",
      "Epoch 64/100\n",
      "669/669 [==============================] - 1s 788us/step - loss: 0.3051 - accuracy: 0.9043\n",
      "Epoch 65/100\n",
      "669/669 [==============================] - 1s 770us/step - loss: 0.2550 - accuracy: 0.9118\n",
      "Epoch 66/100\n",
      "669/669 [==============================] - 1s 766us/step - loss: 0.2640 - accuracy: 0.9208\n",
      "Epoch 67/100\n",
      "669/669 [==============================] - 1s 842us/step - loss: 0.2792 - accuracy: 0.9223\n",
      "Epoch 68/100\n",
      "669/669 [==============================] - 1s 823us/step - loss: 0.2775 - accuracy: 0.9103\n",
      "Epoch 69/100\n",
      "669/669 [==============================] - 1s 815us/step - loss: 0.3180 - accuracy: 0.9043\n",
      "Epoch 70/100\n",
      "669/669 [==============================] - 0s 735us/step - loss: 0.2891 - accuracy: 0.9253\n",
      "Epoch 71/100\n",
      "669/669 [==============================] - 1s 830us/step - loss: 0.2823 - accuracy: 0.9088\n",
      "Epoch 72/100\n",
      "669/669 [==============================] - 1s 755us/step - loss: 0.2882 - accuracy: 0.9178\n",
      "Epoch 73/100\n",
      "669/669 [==============================] - 1s 766us/step - loss: 0.2748 - accuracy: 0.9133\n",
      "Epoch 74/100\n",
      "669/669 [==============================] - 1s 774us/step - loss: 0.3182 - accuracy: 0.8819\n",
      "Epoch 75/100\n",
      "669/669 [==============================] - 1s 781us/step - loss: 0.2840 - accuracy: 0.9193\n",
      "Epoch 76/100\n",
      "669/669 [==============================] - 1s 756us/step - loss: 0.2953 - accuracy: 0.9013\n",
      "Epoch 77/100\n",
      "669/669 [==============================] - 1s 790us/step - loss: 0.3197 - accuracy: 0.9013\n",
      "Epoch 78/100\n",
      "669/669 [==============================] - 1s 750us/step - loss: 0.2684 - accuracy: 0.9178\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 1s 765us/step - loss: 0.2377 - accuracy: 0.9238\n",
      "Epoch 80/100\n",
      "669/669 [==============================] - 0s 693us/step - loss: 0.3189 - accuracy: 0.9073\n",
      "Epoch 81/100\n",
      "669/669 [==============================] - 0s 696us/step - loss: 0.3346 - accuracy: 0.9028\n",
      "Epoch 82/100\n",
      "669/669 [==============================] - 0s 692us/step - loss: 0.2209 - accuracy: 0.9387\n",
      "Epoch 83/100\n",
      "669/669 [==============================] - 0s 725us/step - loss: 0.2771 - accuracy: 0.9073\n",
      "Epoch 84/100\n",
      "669/669 [==============================] - 0s 674us/step - loss: 0.2148 - accuracy: 0.9342\n",
      "Epoch 85/100\n",
      "669/669 [==============================] - 0s 723us/step - loss: 0.2979 - accuracy: 0.9088\n",
      "Epoch 86/100\n",
      "669/669 [==============================] - 0s 720us/step - loss: 0.2908 - accuracy: 0.9253\n",
      "Epoch 87/100\n",
      "669/669 [==============================] - 0s 721us/step - loss: 0.2968 - accuracy: 0.9193\n",
      "Epoch 88/100\n",
      "669/669 [==============================] - 0s 713us/step - loss: 0.2360 - accuracy: 0.9327\n",
      "Epoch 89/100\n",
      "669/669 [==============================] - 0s 687us/step - loss: 0.3407 - accuracy: 0.9058\n",
      "Epoch 90/100\n",
      "669/669 [==============================] - 0s 695us/step - loss: 0.2816 - accuracy: 0.9058\n",
      "Epoch 91/100\n",
      "669/669 [==============================] - 0s 700us/step - loss: 0.2635 - accuracy: 0.8999\n",
      "Epoch 92/100\n",
      "669/669 [==============================] - 0s 695us/step - loss: 0.3299 - accuracy: 0.9043\n",
      "Epoch 93/100\n",
      "669/669 [==============================] - 1s 792us/step - loss: 0.3550 - accuracy: 0.9013\n",
      "Epoch 94/100\n",
      "669/669 [==============================] - 0s 670us/step - loss: 0.2842 - accuracy: 0.9268\n",
      "Epoch 95/100\n",
      "669/669 [==============================] - 0s 729us/step - loss: 0.3294 - accuracy: 0.8969\n",
      "Epoch 96/100\n",
      "669/669 [==============================] - 0s 698us/step - loss: 0.2948 - accuracy: 0.9058\n",
      "Epoch 97/100\n",
      "669/669 [==============================] - 0s 691us/step - loss: 0.2883 - accuracy: 0.9193\n",
      "Epoch 98/100\n",
      "669/669 [==============================] - 0s 725us/step - loss: 0.2552 - accuracy: 0.9208\n",
      "Epoch 99/100\n",
      "669/669 [==============================] - 1s 751us/step - loss: 0.2926 - accuracy: 0.9223\n",
      "Epoch 100/100\n",
      "669/669 [==============================] - 0s 727us/step - loss: 0.2517 - accuracy: 0.9283\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model\n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=5, verbose=1)\n",
    "model.save('chatbot_model_dummy.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actions At Home',\n",
       " 'Actions If At Risk',\n",
       " 'Children',\n",
       " 'Citizen',\n",
       " 'Closed Shops',\n",
       " 'Contact With Infected',\n",
       " 'Conversation',\n",
       " 'Daycare',\n",
       " 'Doctor',\n",
       " 'Educating Children On Coronavirus',\n",
       " 'Fear',\n",
       " 'Gathering Precautions',\n",
       " 'Health Authority Recommendations',\n",
       " 'Illness',\n",
       " 'Incubation Period',\n",
       " 'Infected Twice',\n",
       " 'Infection Prevention',\n",
       " 'Infection Through Food',\n",
       " 'Methods of Transmission',\n",
       " 'Mortality Rate',\n",
       " 'People At Risk',\n",
       " 'Precautions',\n",
       " 'Pregnant',\n",
       " 'Public Spaces',\n",
       " 'Public Transport',\n",
       " 'Purchasing Groceries',\n",
       " 'Report',\n",
       " 'Returning From Travel',\n",
       " 'Sick Child',\n",
       " 'Strategy',\n",
       " 'Student',\n",
       " 'Symptoms',\n",
       " 'Testing',\n",
       " 'Treatment',\n",
       " 'Vacation',\n",
       " 'Visiting Elderly',\n",
       " 'What Do We Know About Coronavirus',\n",
       " 'What Is Coronavirus',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'thanks']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
